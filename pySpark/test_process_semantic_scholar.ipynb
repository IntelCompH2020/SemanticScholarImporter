{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e420d98e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.1.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3a3ebb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a9cb1c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#para volcar un esquema de un df en una variable.\n",
    "#from pyspark.sql.types import StructType\n",
    "#schema = [i for i in df.schema]\n",
    "#schema\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import BooleanType\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "\n",
    "def getFieldsOfStudy (col, field):\n",
    "    #field = 'Mathematics'\n",
    "    return field in col\n",
    "filter_udf_getFieldsOfStudy = udf(getFieldsOfStudy, BooleanType())\n",
    "\n",
    "class readSSC:\n",
    "    __df_   = None\n",
    "    __path_ = None\n",
    "    \n",
    "    \n",
    "    #onlyDois = True se cargan sólo las publicaciones con Dois\n",
    "    def __init__ (self, path, onlyDois = False):\n",
    "        self.__path = path\n",
    "        print ('Cargando los datos desde %s' % (path))\n",
    "        \n",
    "        if onlyDois:\n",
    "            self.__df_ = spark.read.json(path).where('doi<>\"\"')\n",
    "        else:\n",
    "            self.__df_ = spark.read.json(path)\n",
    "            \n",
    "    def count (self):\n",
    "        return self.__df_.count()\n",
    "    \n",
    "    def show (self):\n",
    "        return self.__df_.show (truncate = False)\n",
    "    \n",
    "    def getFirst (self):\n",
    "        return __df_.first()\n",
    "        \n",
    "    def getStructure (self):\n",
    "        return self.getFirst().asDict()\n",
    "    \n",
    "    #fieldOfStury = Mathematics AND/OR Engineering:\n",
    "    #por algún motivo esto no funciona correctamente:\n",
    "    #fieldsOS = [\"Mathematics\",\"Engineering\"]\n",
    "    #math = df.filter(col('fieldsOfStudy').isin(fieldsOS))\n",
    "    def getByArea (self, area1, operator = None, area2=None):\n",
    "        if operator == None:\n",
    "            return self.__df_.where(filter_udf_getFieldsOfStudy(col('fieldsOfStudy'), lit(area1)))\n",
    "        elif operator == 'AND':\n",
    "            return self.__df_.where(filter_udf_getFieldsOfStudy(col('fieldsOfStudy'), lit(area1)) & filter_udf_getFieldsOfStudy(col('fieldsOfStudy'), lit(area2)) )\n",
    "        elif operator == 'OR':\n",
    "            return self.__df_.where(filter_udf_getFieldsOfStudy(col('fieldsOfStudy'), lit(area2)) | filter_udf_getFieldsOfStudy(col('fieldsOfStudy'), lit(area2)) )\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ec7f7709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando los datos desde /export/ml4ds/semanticSC/20211101/\n",
      "encontradas 103634033 entradas\n",
      "encontrados 9169742 registros para Computer Science\n",
      "Duration: 0:22:39.569561\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "#dataDir = '/export/ml4ds/semanticSC/test/'\n",
    "dataDir = '/export/ml4ds/semanticSC/20211101/'\n",
    "area = 'Computer Science'\n",
    "\n",
    "\n",
    "mySSC = readSSC (dataDir, onlyDois = True)\n",
    "print ('encontradas %s entradas' % (mySSC.count()))\n",
    "\n",
    "dfFilterCS = mySSC.getByArea ( area )\n",
    "\n",
    "print ('encontrados %s registros para %s' % (dfFilterCS.count(), area))\n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0b874115",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFilterCS.write.json('prueba.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9d66f202",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFilter1 = mySSC.getByArea ('Mathematics', 'OR', 'Physics')\n",
    "dfFilter2 = mySSC.getByArea ('Computer Science')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "42a62133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2988 / 1773\n"
     ]
    }
   ],
   "source": [
    "print ('%s / %s' % (dfFilter2.count(), dfFilter1.count()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "40a3eaee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+\n",
      "|fieldsOfStudy                           |\n",
      "+----------------------------------------+\n",
      "|[Physics]                               |\n",
      "|[Materials Science, Physics]            |\n",
      "|[Physics]                               |\n",
      "|[Mathematics, Physics]                  |\n",
      "|[Physics, Medicine]                     |\n",
      "|[Physics]                               |\n",
      "|[Physics]                               |\n",
      "|[Physics]                               |\n",
      "|[Physics, Engineering]                  |\n",
      "|[Physics]                               |\n",
      "|[Physics, Computer Science, Mathematics]|\n",
      "|[Physics]                               |\n",
      "|[Physics]                               |\n",
      "|[Physics]                               |\n",
      "|[Physics]                               |\n",
      "|[Medicine, Physics, Materials Science]  |\n",
      "|[Physics]                               |\n",
      "|[Physics]                               |\n",
      "|[Physics]                               |\n",
      "|[Physics, Medicine]                     |\n",
      "+----------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------------------------------+\n",
      "|fieldsOfStudy                  |\n",
      "+-------------------------------+\n",
      "|[Computer Science]             |\n",
      "|[Computer Science, Medicine]   |\n",
      "|[Computer Science]             |\n",
      "|[Computer Science]             |\n",
      "|[Computer Science]             |\n",
      "|[Mathematics, Computer Science]|\n",
      "|[Computer Science]             |\n",
      "|[Computer Science, Medicine]   |\n",
      "|[Computer Science]             |\n",
      "|[Computer Science]             |\n",
      "|[Computer Science]             |\n",
      "|[Mathematics, Computer Science]|\n",
      "|[Computer Science]             |\n",
      "|[Computer Science]             |\n",
      "|[Computer Science]             |\n",
      "|[Computer Science]             |\n",
      "|[Computer Science]             |\n",
      "|[Mathematics, Computer Science]|\n",
      "|[Computer Science]             |\n",
      "|[Computer Science]             |\n",
      "+-------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dfFilter1.select('fieldsOfStudy').show(truncate=False)\n",
    "dfFilter2.select('fieldsOfStudy').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef8d2b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom pyspark.sql.types import StructType,StructField \\nfrom pyspark.sql.types import StringType, IntegerType, ArrayType\\n\\nSchema = [\\n \\n StructField('authors',ArrayType(StructType((StructField('ids',ArrayType(StringType,True),True),StructField(name,StringType,True),StructField(structuredName,StringType,True))),True),True),\\n StructField(doi,StringType,True),\\n StructField(doiUrl,StringType,True),\\n StructField(entities,ArrayType(StringType,True),True),\\n StructField(fieldsOfStudy,ArrayType(StringType,True),True),\\n StructField(id,StringType,True),\\n StructField(inCitations,ArrayType(StringType,True),True),\\n StructField(journalName,StringType,True),\\n StructField(journalPages,StringType,True),\\n StructField(journalVolume,StringType,True),\\n StructField(magId,StringType,True),\\n StructField(outCitations,ArrayType(StringType,True),True),\\n StructField(paperAbstract,StringType,True),\\n StructField(pdfUrls,ArrayType(StringType,True),True),\\n StructField(pmid,StringType,True),\\n StructField(s2PdfUrl,StringType,True),\\n StructField(s2Url,StringType,True),\\n StructField(sources,ArrayType(StringType,True),True),\\n StructField(title,StringType,True),\\n StructField(venue,StringType,True),\\n StructField(year,LongType,True)]\\n \""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from pyspark.sql.types import StructType,StructField \n",
    "from pyspark.sql.types import StringType, IntegerType, ArrayType\n",
    "\n",
    "Schema = [\n",
    " \n",
    " StructField('authors',ArrayType(StructType((StructField('ids',ArrayType(StringType,True),True),StructField(name,StringType,True),StructField(structuredName,StringType,True))),True),True),\n",
    " StructField(doi,StringType,True),\n",
    " StructField(doiUrl,StringType,True),\n",
    " StructField(entities,ArrayType(StringType,True),True),\n",
    " StructField(fieldsOfStudy,ArrayType(StringType,True),True),\n",
    " StructField(id,StringType,True),\n",
    " StructField(inCitations,ArrayType(StringType,True),True),\n",
    " StructField(journalName,StringType,True),\n",
    " StructField(journalPages,StringType,True),\n",
    " StructField(journalVolume,StringType,True),\n",
    " StructField(magId,StringType,True),\n",
    " StructField(outCitations,ArrayType(StringType,True),True),\n",
    " StructField(paperAbstract,StringType,True),\n",
    " StructField(pdfUrls,ArrayType(StringType,True),True),\n",
    " StructField(pmid,StringType,True),\n",
    " StructField(s2PdfUrl,StringType,True),\n",
    " StructField(s2Url,StringType,True),\n",
    " StructField(sources,ArrayType(StringType,True),True),\n",
    " StructField(title,StringType,True),\n",
    " StructField(venue,StringType,True),\n",
    " StructField(year,LongType,True)]\n",
    " '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c387046",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = '/export/ml4ds/semanticSC/test/'\n",
    "df = spark.read.json(dataDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0300a65c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65981"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff99f499",
   "metadata": {},
   "outputs": [],
   "source": [
    "first = df.first()\n",
    "campos = list(first.asDict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c8439bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['authors',\n",
       " 'doi',\n",
       " 'doiUrl',\n",
       " 'entities',\n",
       " 'fieldsOfStudy',\n",
       " 'id',\n",
       " 'inCitations',\n",
       " 'journalName',\n",
       " 'journalPages',\n",
       " 'journalVolume',\n",
       " 'magId',\n",
       " 'outCitations',\n",
       " 'paperAbstract',\n",
       " 'pdfUrls',\n",
       " 'pmid',\n",
       " 's2PdfUrl',\n",
       " 's2Url',\n",
       " 'sources',\n",
       " 'title',\n",
       " 'venue',\n",
       " 'year']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "campos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ab426888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(first.fieldsOfStudy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d3ebf82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "withDoi = df.select('*').filter('doi<>\"\"').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "efea0303",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import BooleanType\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "def getFieldsOfStudy (col, field):\n",
    "        #field = 'Mathematics'\n",
    "        return field in col\n",
    "    \n",
    "\n",
    "filter_udf_getFieldsOfStudy = udf(getFieldsOfStudy, BooleanType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "551fb478",
   "metadata": {},
   "outputs": [],
   "source": [
    "math = StructField('Mathematics', StringType(), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "71d39e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "#df.where((col(\"foo\") > 0) | (col(\"bar\") < 0))\n",
    "\n",
    "\n",
    "maths = df.where(filter_udf_getFieldsOfStudy(col('fieldsOfStudy'), lit('Mathematics')) & filter_udf_getFieldsOfStudy(col('fieldsOfStudy'), lit('Engineering')) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f93d8dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maths.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "32e76472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------+\n",
      "|fieldsOfStudy                                        |\n",
      "+-----------------------------------------------------+\n",
      "|[Mathematics, Engineering]                           |\n",
      "|[Engineering, Mathematics]                           |\n",
      "|[Mathematics, Engineering]                           |\n",
      "|[Mathematics, Engineering]                           |\n",
      "|[Computer Science, Mathematics, Physics, Engineering]|\n",
      "|[Mathematics, Computer Science, Engineering]         |\n",
      "|[Mathematics, Engineering]                           |\n",
      "|[Computer Science, Engineering, Mathematics]         |\n",
      "|[Engineering, Mathematics]                           |\n",
      "|[Computer Science, Engineering, Mathematics]         |\n",
      "|[Computer Science, Engineering, Mathematics]         |\n",
      "|[Mathematics, Engineering, Computer Science]         |\n",
      "|[Engineering, Mathematics]                           |\n",
      "|[Mathematics, Engineering]                           |\n",
      "|[Mathematics, Engineering]                           |\n",
      "|[Mathematics, Engineering]                           |\n",
      "|[Mathematics, Engineering]                           |\n",
      "|[Engineering, Mathematics]                           |\n",
      "|[Mathematics, Engineering]                           |\n",
      "+-----------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "maths.select('fieldsOfStudy').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a2dd7a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "cannot resolve '`Mathematics`' given input columns: [authors, doi, doiUrl, entities, fieldsOfStudy, id, inCitations, journalName, journalPages, journalVolume, magId, outCitations, paperAbstract, pdfUrls, pmid, s2PdfUrl, s2Url, sources, title, venue, year];\n'Filter getFieldsOfStudy(fieldsOfStudy#18, 'Mathematics)\n+- Relation[authors#14,doi#15,doiUrl#16,entities#17,fieldsOfStudy#18,id#19,inCitations#20,journalName#21,journalPages#22,journalVolume#23,magId#24,outCitations#25,paperAbstract#26,pdfUrls#27,pmid#28,s2PdfUrl#29,s2Url#30,sources#31,title#32,venue#33,year#34L] json\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-47a138b903a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mauthors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter_udf_getFieldsOfStudy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fieldsOfStudy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Mathematics'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/spark-3.1.1-bin-2.8.3/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mfilter\u001b[0;34m(self, condition)\u001b[0m\n\u001b[1;32m   1715\u001b[0m             \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1716\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1717\u001b[0;31m             \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1718\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1719\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"condition should be string or Column\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-3.1.1-bin-2.8.3/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-3.1.1-bin-2.8.3/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: cannot resolve '`Mathematics`' given input columns: [authors, doi, doiUrl, entities, fieldsOfStudy, id, inCitations, journalName, journalPages, journalVolume, magId, outCitations, paperAbstract, pdfUrls, pmid, s2PdfUrl, s2Url, sources, title, venue, year];\n'Filter getFieldsOfStudy(fieldsOfStudy#18, 'Mathematics)\n+- Relation[authors#14,doi#15,doiUrl#16,entities#17,fieldsOfStudy#18,id#19,inCitations#20,journalName#21,journalPages#22,journalVolume#23,magId#24,outCitations#25,paperAbstract#26,pdfUrls#27,pmid#28,s2PdfUrl#29,s2Url#30,sources#31,title#32,venue#33,year#34L] json\n"
     ]
    }
   ],
   "source": [
    "authors = df.filter(filter_udf_getFieldsOfStudy('fieldsOfStudy', 'Mathematics'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39711a41",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "cannot resolve '(`fieldsOfStudy` IN ('Mathematics', 'Engineering'))' due to data type mismatch: Arguments must be same type but were: array<string> != string;\n'Filter fieldsOfStudy#18 IN (Mathematics,Engineering)\n+- Relation[authors#14,doi#15,doiUrl#16,entities#17,fieldsOfStudy#18,id#19,inCitations#20,journalName#21,journalPages#22,journalVolume#23,magId#24,outCitations#25,paperAbstract#26,pdfUrls#27,pmid#28,s2PdfUrl#29,s2Url#30,sources#31,title#32,venue#33,year#34L] json\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-5756fa3b7548>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfieldsOS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Mathematics\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Engineering\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fieldsOfStudy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfieldsOS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/spark-3.1.1-bin-2.8.3/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mfilter\u001b[0;34m(self, condition)\u001b[0m\n\u001b[1;32m   1715\u001b[0m             \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1716\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1717\u001b[0;31m             \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1718\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1719\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"condition should be string or Column\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-3.1.1-bin-2.8.3/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-3.1.1-bin-2.8.3/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: cannot resolve '(`fieldsOfStudy` IN ('Mathematics', 'Engineering'))' due to data type mismatch: Arguments must be same type but were: array<string> != string;\n'Filter fieldsOfStudy#18 IN (Mathematics,Engineering)\n+- Relation[authors#14,doi#15,doiUrl#16,entities#17,fieldsOfStudy#18,id#19,inCitations#20,journalName#21,journalPages#22,journalVolume#23,magId#24,outCitations#25,paperAbstract#26,pdfUrls#27,pmid#28,s2PdfUrl#29,s2Url#30,sources#31,title#32,venue#33,year#34L] json\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "fieldsOS = [\"Mathematics\",\"Engineering\"]\n",
    "math = df.filter(col('fieldsOfStudy').isin(fieldsOS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb8df87f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(authors,ArrayType(StructType(List(StructField(ids,ArrayType(StringType,true),true),StructField(name,StringType,true),StructField(structuredName,StringType,true))),true),true),StructField(doi,StringType,true),StructField(doiUrl,StringType,true),StructField(entities,ArrayType(StringType,true),true),StructField(fieldsOfStudy,ArrayType(StringType,true),true),StructField(id,StringType,true),StructField(inCitations,ArrayType(StringType,true),true),StructField(journalName,StringType,true),StructField(journalPages,StringType,true),StructField(journalVolume,StringType,true),StructField(magId,StringType,true),StructField(outCitations,ArrayType(StringType,true),true),StructField(paperAbstract,StringType,true),StructField(pdfUrls,ArrayType(StringType,true),true),StructField(pmid,StringType,true),StructField(s2PdfUrl,StringType,true),StructField(s2Url,StringType,true),StructField(sources,ArrayType(StringType,true),true),StructField(title,StringType,true),StructField(venue,StringType,true),StructField(year,LongType,true)))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "85238e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+\n",
      "|fieldsOfStudy             |\n",
      "+--------------------------+\n",
      "|[Mathematics]             |\n",
      "|[Mathematics]             |\n",
      "|[Mathematics]             |\n",
      "|[Mathematics]             |\n",
      "|[Mathematics]             |\n",
      "|[Mathematics]             |\n",
      "|[Mathematics]             |\n",
      "|[Mathematics]             |\n",
      "|[Mathematics]             |\n",
      "|[Mathematics]             |\n",
      "|[Engineering, Mathematics]|\n",
      "|[Mathematics]             |\n",
      "|[Mathematics]             |\n",
      "|[Mathematics]             |\n",
      "|[Economics, Mathematics]  |\n",
      "|[Mathematics]             |\n",
      "|[Mathematics]             |\n",
      "|[Mathematics]             |\n",
      "|[Mathematics]             |\n",
      "|[Mathematics]             |\n",
      "+--------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pubWithDOI_Math.select(df.fieldsOfStudy).show(truncate = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

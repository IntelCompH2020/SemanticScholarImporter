{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e420d98e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.1.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "01b97d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pyspark.sql.types import StringType, ArrayType\n",
    "import pyspark.sql.functions as F\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d598a2d",
   "metadata": {},
   "source": [
    "### Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b9359870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aux functions\n",
    "def normalize(text):\n",
    "    if isinstance(text, str):\n",
    "        text = \" \".join(text.split())\n",
    "    return text\n",
    "\n",
    "\n",
    "take_id = F.udf(lambda x: normalize(x[0] if len(x) > 0 else None), StringType())\n",
    "take_authors_ids = F.udf(\n",
    "    lambda x: [normalize(el[0] if len(el) > 0 else None) for el in x],\n",
    "    ArrayType(StringType()),\n",
    ")\n",
    "norm_string = F.udf(normalize, StringType())\n",
    "\n",
    "\n",
    "def get_pdf(pdf_list):\n",
    "    pdf_list = [pdf for pdf in pdf_list if pdf.endswith(\".pdf\")]\n",
    "    if len(pdf_list) > 0:\n",
    "        return pdf_list[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "get_first_pdf = F.udf(get_pdf, StringType())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fbb4ea",
   "metadata": {},
   "source": [
    "### Define directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "676a60c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_data = \"/export/ml4ds/semanticSC/test/\"\n",
    "dir_out = Path(\"/export/ml4ds/semanticSC/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27f3c4b",
   "metadata": {},
   "source": [
    "### Read data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4c387046",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "65981"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.json(dir_data)\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e528dff6",
   "metadata": {},
   "source": [
    "### Save authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b41da632",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_authors = df.select(F.explode(\"authors\").alias(\"authors\"))\n",
    "df_authors = (\n",
    "    df_authors.select(\"authors.ids\", \"authors.name\")\n",
    "    .withColumn(\"ids\", take_id(\"ids\"))\n",
    "    .withColumn(\"name\", norm_string(\"name\"))\n",
    "    .withColumnRenamed(\"ids\", \"id\")\n",
    "    .drop_duplicates(subset=[\"id\"])\n",
    "    .dropna(subset=[\"id\"])\n",
    ")\n",
    "df_authors.write.parquet(\n",
    "    dir_out.joinpath(\"parquet/authors.parquet\").as_posix(), mode=\"overwrite\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c662d1e3",
   "metadata": {},
   "source": [
    "### Save papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5a6e36ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"id\",\n",
    "    \"title\",\n",
    "    \"paperAbstract\",\n",
    "    \"s2Url\",\n",
    "    \"pdfUrls\",\n",
    "    \"year\",\n",
    "    \"sources\",\n",
    "    \"doi\",\n",
    "    \"doiUrl\",\n",
    "    \"pmid\",\n",
    "    \"magId\",\n",
    "    \"fieldsOfStudy\",\n",
    "    \"journalName\",\n",
    "    \"journalPages\",\n",
    "    \"journalVolume\",\n",
    "    \"venue\",\n",
    "    \"inCitations\",\n",
    "    \"outCitations\",\n",
    "    \"authors\",\n",
    "]\n",
    "df_papers = df.select(columns)\n",
    "df_papers = df_papers.withColumn(\"authors\", take_authors_ids(\"authors.ids\"))\n",
    "for c in columns:\n",
    "    if df.select(c).dtypes[0][1] == \"string\":\n",
    "        df_papers = df_papers.withColumn(c, norm_string(c))\n",
    "\n",
    "df_papers.write.parquet(\n",
    "    dir_out.joinpath(\"parquet/papers.parquet\").as_posix(),\n",
    "    mode=\"overwrite\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c481351",
   "metadata": {},
   "source": [
    "### Download PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8c6fa0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+-----------------------------------------------------------------------------------------------------------------+\n",
      "|id                                      |pdfUrls                                                                                                          |\n",
      "+----------------------------------------+-----------------------------------------------------------------------------------------------------------------+\n",
      "|e15212675135c612e335436e7a3f96b3b1c3e5b0|https://researchmgt.monash.edu/ws/portalfiles/portal/283970231/283970065_oa.pdf                                  |\n",
      "|2c04fba10f6ccbd1d0d990862e4b6ae60e2c92c1|https://static-content.springer.com/esm/art:10.1186%2Fs13148-015-0077-1/MediaObjects/13148_2015_77_MOESM6_ESM.pdf|\n",
      "|9e93efb038e37a50e0cd846a48eabd8a61382a74|http://circ.ahajournals.org/content/circulationaha/90/6/3070.full.pdf                                            |\n",
      "|7f3155dbc72404cd86bc070ac172de5e918f6251|http://www.dmi.unisa.it/people/gerla/www/Down/breveclosure.pdf                                                   |\n",
      "|6df3863df194df4d09fdd594babe0d2321b550a3|http://www.dafx14.fau.de/papers/dafx14_alex_wilson_categorisation_of_distort.pdf                                 |\n",
      "+----------------------------------------+-----------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pdf_urls = (\n",
    "    df.select([\"id\", \"pdfUrls\"])\n",
    "    .withColumn(\"pdfUrls\", get_first_pdf(\"pdfUrls\"))\n",
    "    .filter(F.length(\"pdfUrls\") > 0)\n",
    ")\n",
    "# pdf_urls.show(5, truncate=False)\n",
    "\n",
    "def download_pdf(x):\n",
    "    r = requests.get(x[\"pdfUrls\"], stream=True)\n",
    "\n",
    "    with dir_out.joinpath(f\"pdfs/{x['id']}.pdf\").open(\"wb\") as f:\n",
    "        f.write(r.content)\n",
    "\n",
    "pdf_urls.foreach(download_pdf)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

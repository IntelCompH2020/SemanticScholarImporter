[database]
# dbuser:   Username
# dbpass:   Password
# dbhost:   Host name or IP
# dbport:   Port
# dbname:   Database name

dbuser = 
dbpass = 
dbhost = 
dbport = 
dbname = 


[data]
# dir_data:     Directory where raw files will be stored
# version:      Version of data to be used/downloaded
#                   last: the last version will be used
#                   date: in format YYYY-MM-DD

dir_data = ../Datasets/SemanticScholar
version = last

[import]
# Settings for efficient loading into the Postgres database
# These settings are not used for Spark processing
# ncpu:         Number of cores for parallel processing
#               Set to 0 to deactivate parallel processing
# chunksize:    Size of chunks for paper processing and database ingestion
ncpu = 4
chunksize = 100000

[spark]
# dir_data:     Directory where raw files will be stored by version.
#               Downloaded PDFs will be stored in dir_data/pdfs
#               Example tree:
#               dir_data:
#                | - 20220201
#                   | - corpus1.zip
#                   | - corpus2.zip
#                | - pdfs
#                   | - doc1.pdf
#                   | - doc2.pdf
#
# dir_parquet:  Directory of output parquet files.
#               Example tree:
#               dir_parquet:
#                | - 20220201
#                   | - authors.parquet
#                   | - papers.parquet
#
# version:      Version of data to be used/downloaded
#                   last: the last version will be used
#                   date: in format YYYY-MM-DD
dir_data = /export/ml4ds/IntelComp/Datalake/SemanticScholar/rawdata
dir_parquet = /export/ml4ds/IntelComp/Datalake/SemanticScholar/parquet_prueba
version = 20220201

[downloadS2]
dir_data = 
S2_API_KEY = 
version = latest





[database]
# dbuser:   Username
# dbpass:   Password
# dbhost:   Host name or IP
# dbport:   Port
# dbname:   Database name

dbuser = 
dbpass = 
dbhost = 
dbport = 
dbname = 

[import]
# Settings for efficient loading into the Postgres database
# These settings are not used for Spark processing
# ncpu:         Number of cores for parallel processing
#               Set to 0 to deactivate parallel processing
# chunksize:    Size of chunks for paper processing and database ingestion
ncpu = 4
chunksize = 100000

[spark]
# dir_data:     Directory where raw files will be stored by version.
# dir_parquet:  Directory of output parquet files.
# version:      Version of data to be used/downloaded
#                   last: the last version will be used
#                   date: in format YYYY-MM-DD
# dir_pdfs:     Directory where downloaded PDFs will be stored

# Example tree:
#   global_dir:
#   | - dir_data:
#       | - 20220201
#           | - corpus1.zip
#           | - corpus2.zip
#   | - dir_parquet:
#       | - 20220201
#           | - authors.parquet
#           | - papers.parquet

dir_data = /export/ml4ds/IntelComp/Datalake/SemanticScholar/rawdata
dir_parquet = /export/ml4ds/IntelComp/Datalake/SemanticScholar/parquet_prueba
version = 20220201
dir_pdfs = /export/data_ml4ds/IntelComp/Datasets/semanticscholar/rawdata/pdfs/
